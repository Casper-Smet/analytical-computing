{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Forward Propagation\nUsing matrix-vector multiplication. \u003cbr\u003e\n$\\vec{x} \\leftarrow$ input-layer / vector \u003cbr\u003e\n$L_{n} \\leftarrow$ hidden layer $n$ / matrix \u003cbr\u003e\n$\\vec{y}\u003dL_{2} \\cdot L_{1} \\cdot \\vec{x} \\leftarrow$ output-layer / vector",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[0.62, 0.35999999999999993]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import json\nimport numpy as np\nimport pprint\n\nwith open(r\"example-2layer.json\", \"r\") as read_file:\n    example \u003d json.load(read_file)\n\ninput_layer \u003d list()\nfor a in range(int(example.get(\"layer1\").get(\"size_in\"))):\n    input_layer.append(1)\n\ninput_layer \u003d np.array(input_layer)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Input and hidden layers\n$\\vec{x} \u003d \\begin{bmatrix} 1\\\\1\\\\1\\\\1\\\\1 \\end{bmatrix}$ \u003cbr\u003e\n$L_{1} \u003d \\begin{bmatrix} \n0.5\u00260.2\u00260\u00260\u0026-0.2\\\\\n0.2\u0026-0.5\u0026-0.1\u00260.9\u0026-0.8\\\\\n0\u00260.2\u00260\u00260.1\u0026-0.1\\\\\n0.1\u00260.8\u00260.3\u00260\u0026-0.7\\end{bmatrix}, L_{2} \u003d \\begin{bmatrix} 0.5\u00260.2\u0026-0.1\u00260.9\\\\ 0.2\u0026-0.5\u00260.3\u00260.1 \\end{bmatrix}$\n\u003cbr\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def generate_weight_matrix(layer_string):\n    weights \u003d list()\n    for size in range(int(example.get(layer_string).get(\"size_in\"))):\n        weights.append(list(\u00270\u0027 * int(example.get(layer_string).get(\"size_out\"))))\n\n    for weight in example.get(layer_string).get(\"weights\"):\n        for w in example.get(layer_string).get(\"weights\").get(weight):\n            weights[int(weight) - 1][int(w) - 1] \u003d example.get(layer_string).get(\"weights\").get(weight).get(w)\n\n    weights \u003d np.array(weights)\n    transposed_weights \u003d np.transpose(weights)\n    return transposed_weights\n\n\n# Weight matrix layer 1:\nmatrix_layer1 \u003d generate_weight_matrix(\"layer1\")\n# Weight matrix layer 2:\nmatrix_layer2 \u003d generate_weight_matrix(\"layer2\")\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Forward propagation using one layer\nWhere the matrix is $n \\times m$ and the vector is $m \\times 1$\u003cbr\u003e\n$L_{1} \\cdot \\vec{x} \u003d \\vec{y}$ \u003cbr\u003e\n$\\vec{y} \u003d \\begin{bmatrix} \n0.5\u00260.2\u00260\u00260\u0026-0.2\\\\\n0.2\u0026-0.5\u0026-0.1\u00260.9\u0026-0.8\\\\\n0\u00260.2\u00260\u00260.1\u0026-0.1\\\\\n0.1\u00260.8\u00260.3\u00260\u0026-0.7\\end{bmatrix} \\cdot \\begin{bmatrix} 1\\\\1\\\\1\\\\1\\\\1 \\end{bmatrix}$\n\u003e$\u003d \\begin{bmatrix} 1 \\cdot 0.5 + 1 \\cdot 0.2 + 1 \\cdot 0  + 1 \\cdot 0 + 1 \\cdot -0.2\\\\\n   1 \\cdot 0.2 + 1 \\cdot -0.5 + 1 \\cdot -0.1 + 1 \\cdot 0.9 + 1 \\cdot -0.8\\\\\n   1 \\cdot 0 + 1 \\cdot 0.2 + 1 \\cdot 0 + 1 \\cdot 0.1 + 1 \\cdot -0.1\\\\\n   1 \\cdot 0.1 + 1 \\cdot 0.8 + 1 \\cdot 0.3 + 1 \\cdot 0 + 1 \\cdot -0.7\\end{bmatrix}$\n   \n$\\vec{y} \u003d \\begin{bmatrix} 0.5\\\\-0.3\\\\0.2\\\\0.5 \\end{bmatrix}$",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def matrix_vector_product(activation, weights):\n    output_layer \u003d list()\n    for w in weights:\n        vector \u003d 0.0\n        for a in range(len(activation)):\n            vector1 \u003d float(float(activation[a]) * float(w[a]))\n            vector +\u003d vector1\n        output_layer.append(vector)\n    return output_layer\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# For one layer:\noutput_layer_1 \u003d matrix_vector_product(input_layer, matrix_layer1)\npprint.pprint(output_layer_1)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Forward propagation using two layers\nThere are atleast two methods for calculating forward propagation with multiple hidden layers. \u003cbr\u003e\n1. Use the output vector from layer n to active layer n+1 (matrix-vector-product).\n2. Turn the layers into one layer using matrix multiplication (matrix-matrix-product).\n\n### Method 1:\n--\nUsing the output vector from [\u0027Forward propagation using one layer\u0027](#Forward-propagation-using-one-layer) as $\\vec{x}$\nand $L_{2}$ for the matrix. \u003cbr\u003e\n$\\vec{x} \u003d \\begin{bmatrix} 0.5\\\\-0.3\\\\0.2\\\\0.5 \\end{bmatrix}$\u003cbr\u003e\n$L_{2} \\cdot \\vec{x} \u003d \\vec{y}$ \u003cbr\u003e\n$\\vec{y} \u003d \\begin{bmatrix} 0.5\u00260.2\u0026-0.1\u00260.9\\\\ 0.2\u0026-0.5\u00260.3\u00260.1 \\end{bmatrix} \\cdot \n\\begin{bmatrix} 0.5\\\\-0.3\\\\0.2\\\\0.5 \\end{bmatrix}$ \n\u003e$\u003d \\begin{bmatrix}0.5 \\cdot 0.5 + 0.2 \\cdot -0.3 + -0.1 \\cdot 0.2  + 0.9 \\cdot 0.5\\\\\n0.2 \\cdot 0.5 + -0.5 \\cdot -0.3 + 0.3 \\cdot 0.2 + 0.1 \\cdot 0.5\n\\end{bmatrix}$\n\n$\\vec{y} \u003d \\begin{bmatrix} 0.62\\\\0.36 \\end{bmatrix}$ \u003cbr\u003e\nDue to floating point inaccuracy, the outcome of the Python script will probably differ by a small amount. This is also\ntrue of the 2nd method.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# When layer 1\u0027s output is used as input vector:\npprint.pprint(matrix_vector_product(np.transpose(output_layer_1), matrix_layer2))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Method 2:\nThis method multiplies $L_{2}$ with $L_{1}$ and the result (matrix) with $\\vec{x}$.\u003cbr\u003e\nMatrix-matrix product requires matrix A to have the dimensions $m\\times n$, matrix B $n\\times p$ and the resulting \nmatrix AB $m\\times p$. \u003cbr\u003e\nMatrix-matrix product can, thankfully (saves on code), be turned into a couple of matrix-vector products. \u003cbr\u003e\n$L_{1} \u003d \\begin{bmatrix} \n0.5\u00260.2\u00260\u00260\u0026-0.2\\\\\n0.2\u0026-0.5\u0026-0.1\u00260.9\u0026-0.8\\\\\n0\u00260.2\u00260\u00260.1\u0026-0.1\\\\\n0.1\u00260.8\u00260.3\u00260\u0026-0.7\\end{bmatrix} \u003d \\begin{bmatrix} \n \\begin{bmatrix} 0.5\\\\0.2\\\\0\\\\0.1 \\end{bmatrix}\n \\begin{bmatrix} 0.2\\\\-0.5\\\\0.2\\\\0.8 \\end{bmatrix} \n \\begin{bmatrix} 0\\\\-0.1\\\\0\\\\0.3 \\end{bmatrix}\n \\begin{bmatrix} 0\\\\0.9\\\\0.1\\\\0 \\end{bmatrix} \n \\begin{bmatrix} -0.2\\\\-0.8\\\\-0.1\\\\-0.7\\end{bmatrix} \\end{bmatrix}$ \u003cbr\u003e\n $L_{1\\space 2} \u003d L_{2}\\cdot L_{1}$\n \u003e$\u003d\\begin{bmatrix} 0.5\u00260.2\u0026-0.1\u00260.9\\\\ 0.2\u0026-0.5\u00260.3\u00260.1 \\end{bmatrix} \\cdot \\begin{bmatrix} \n0.5\u00260.2\u00260\u00260\u0026-0.2\\\\\n0.2\u0026-0.5\u0026-0.1\u00260.9\u0026-0.8\\\\\n0\u00260.2\u00260\u00260.1\u0026-0.1\\\\\n0.1\u00260.8\u00260.3\u00260\u0026-0.7\\end{bmatrix}$ \u003cbr\u003e\n$\u003d\\begin{bmatrix} 0.5\u00260.2\u0026-0.1\u00260.9\\\\ 0.2\u0026-0.5\u00260.3\u00260.1 \\end{bmatrix} \\cdot \\begin{bmatrix} \n \\begin{bmatrix} 0.5\\\\0.2\\\\0\\\\0.1 \\end{bmatrix}\n \\begin{bmatrix} 0.2\\\\-0.5\\\\0.2\\\\0.8 \\end{bmatrix} \n \\begin{bmatrix} 0\\\\-0.1\\\\0\\\\0.3 \\end{bmatrix}\n \\begin{bmatrix} 0\\\\0.9\\\\0.1\\\\0 \\end{bmatrix} \n \\begin{bmatrix} -0.2\\\\-0.8\\\\-0.1\\\\-0.7\\end{bmatrix} \\end{bmatrix} $\u003cbr\u003e\n $\u003d\\begin{bmatrix} \n L_{2} \\cdot \\begin{bmatrix} 0.5\\\\0.2\\\\0\\\\0.1 \\end{bmatrix}\u0026 \n L_{2} \\cdot \\begin{bmatrix} 0.2\\\\-0.5\\\\0.2\\\\0.8 \\end{bmatrix} \u0026\n L_{2} \\cdot \\begin{bmatrix} 0\\\\-0.1\\\\0\\\\0.3 \\end{bmatrix} \u0026\n L_{2} \\cdot \\begin{bmatrix} 0\\\\0.9\\\\0.1\\\\0 \\end{bmatrix} \u0026\n L_{2} \\cdot \\begin{bmatrix} -0.2\\\\-0.8\\\\-0.1\\\\-0.7\\end{bmatrix} \\end{bmatrix} $ \n \n $L_{1\\space 2} \u003d \\begin{bmatrix} \n 0.38\u00260.7\u00260.25\u00260.17\u0026-0.88\\\\ \n 0.01\u00260.43\u00260.08\u0026-0.42\u00260.26\n \\end{bmatrix}$",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def matrix_matrix_product(matrix1, matrix2):\n    # pprint.pprint(matrix1)\n    # pprint.pprint(matrix2)\n    matrix_product \u003d list()\n    for column in np.transpose(matrix2):\n        matrix_product.append(matrix_vector_product(column, matrix1))\n    matrix_product \u003d np.array(matrix_product)\n    return np.transpose(matrix_product)\n\nmatrix_l1_l2 \u003d matrix_matrix_product(matrix_layer2, matrix_layer1)\n# Multiplied weights:\npprint.pprint(matrix_l1_l2)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": " #### Using the new matrix to get the output vector:\n $\\vec{y} \u003d L_{1\\space 2} \\cdot \\vec{x}$ \u003cbr\u003e\n \u003e$\\begin{bmatrix} \n 0.38\u00260.7\u00260.25\u00260.17\u0026-0.88\\\\ \n 0.01\u00260.43\u00260.08\u0026-0.42\u00260.26\n \\end{bmatrix} \\cdot \\begin{bmatrix} 1\\\\1\\\\1\\\\1\\\\1 \\end{bmatrix}$\u003cbr\u003e\n \n $\\vec{y} \u003d \\begin{bmatrix} 0.62\\\\0.36 \\end{bmatrix}$ \u003cbr\u003e\n Just like expected, the resulting vector is the same as that given by method 1. As aforementioned, there is a slight\n discrepancy when calculated by the script.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# Using the matrix-matrix-product:\npprint.pprint(matrix_vector_product(input_layer, matrix_l1_l2))\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}